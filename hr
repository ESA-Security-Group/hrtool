#!/usr/bin/env bash
#
# hr.sh
#
# Hanson Robotics software stack management tool

set -e

BASEDIR=$(dirname $(readlink -f ${BASH_SOURCE[0]}))

############# Configurations #############
DEFAULT_HR_WORKSPACE=$HOME/hansonrobotics
USER_DATA_DIR=$HOME/.hr
HR_PREFIX=/opt/hansonrobotics

OPENCOG_REPOS=(cogutils atomspace opencog ros-behavior-scripting relex external-tools)
HR_REPOS=(HEAD)
HEAD_PACKAGES=(head-hr head-hr-ext head-hr-msgs head-saliency-tracker head-chatbot head-motor-control head-sound head-python-ttsserver)

GITHUB_STORAGE_URL=https://raw.githubusercontent.com/hansonrobotics/binary_dependency/master
GITHUB_STORAGE2_URL=https://$GITHUB_TOKEN@raw.githubusercontent.com/hansonrobotics/binary_dependency2/master
declare -A MD5SUMS

HR_ENVFILE_PATH=$USER_DATA_DIR/env.sh
HR_CACHE=$USER_DATA_DIR/cache
HR_MODELS=$USER_DATA_DIR/models

HR_PY2_VIRTUALENV=$HR_PREFIX/py2env
HR_PY3_VIRTUALENV=$HR_PREFIX/py3env
PIP2=$HR_PY2_VIRTUALENV/bin/pip
PIP3=$HR_PY3_VIRTUALENV/bin/pip3
PYTHON2=$HR_PY2_VIRTUALENV/bin/python
PYTHON3=$HR_PY2_VIRTUALENV/bin/python3

if [[ -z $ROS_PKG_PREFIX ]]; then
    ROS_PKG_PREFIX=$HR_PREFIX/ros
fi

# vision tools
VISION_TOOL_PREFIX=$HR_PREFIX/vision
DLIB_DIR=$VISION_TOOL_PREFIX/dlib
TORCH_DIR=$VISION_TOOL_PREFIX/torch
OPENFACE_DIR=$VISION_TOOL_PREFIX/openface
CPPMT_DIR=$VISION_TOOL_PREFIX/CppMT
EMOTIME_DIR=$VISION_TOOL_PREFIX/emotime
OPENBR_SRC_DIR=$VISION_TOOL_PREFIX/openbr
CLANDMARK_DIR=$VISION_TOOL_PREFIX/clandmark
MARKY_MARKOV_DIR=$HR_PREFIX/marky_markov
DLIB_VERSION=19.0

export PKG_CONFIG_PATH=${HR_PREFIX}/lib/pkgconfig:${PKG_CONFIG_PATH}
export DLIB_PATH=$DLIB_DIR/dlib-${DLIB_VERSION}

# Needed for compiling
export OpenBR_DIR=$HR_PREFIX/share/openbr/cmake
export CMAKE_PREFIX_PATH=$CMAKE_PREFIX_PATH:$HR_PREFIX
export MANYEARSLIB_PREFIX=$HR_PREFIX/manyears-C-1.0.0
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HR_PREFIX/lib:$CPPMT_DIR:$EMOTIME_DIR/build/src:$CLANDMARK_DIR/lib

INCLUDE_DIRS=($EMOTIME_DIR/src/{facedetector,utils,gaborbank,detector,training})
INCLUDE_PATH=$(printf "%s:" "${INCLUDE_DIRS[@]}")
export CPLUS_INCLUDE_PATH=$CPLUS_INCLUDE_PATH:$HR_PREFIX/include:$CPPMT_DIR:$EMOTIME_DIR/include:$CLANDMARK_DIR/include:$INCLUDE_PATH
export CPATH=$CPLUS_INCLUDE_PATH
export LIBRARY_PATH=$LIBRARY_PATH:$HR_PREFIX/lib:$CLANDMARK_DIR/lib/:$CPPMT_DIR:$EMOTIME_DIR/build/src
export PATH=/usr/lib/ccache:$PATH

if [[ -z $ASSUME_YES ]]; then
    ASSUME_YES=0
fi

folder_to_create=($USER_DATA_DIR $HR_CACHE $HR_MODELS $HR_PREFIX)
for d in ${folder_to_create[@]}; do
    if [[ ! -d $d ]]; then
        mkdir -p $d
    fi
done

APT_GET_OPTS="-y"
############# End of Configurations #############

############# Common #############
COLOR_INFO='\033[32m'
COLOR_WARN='\033[33m'
COLOR_ERROR='\033[31m'
COLOR_RESET='\033[0m'
info() {
    printf "${COLOR_INFO}[INFO] ${1}${COLOR_RESET}\n"
}
warn() {
    printf "${COLOR_WARN}[WARN] ${1}${COLOR_RESET}\n"
}
error() {
    printf "${COLOR_ERROR}[ERROR] ${1}${COLOR_RESET}\n"
}

SUDO=""
if [[ $(id -u) != 0 ]]; then
    SUDO="sudo"
fi

md5str() {
  local FNAME=$1
  case $(uname) in
    "Linux")
      echo $(md5sum "$FNAME" | cut -d ' ' -f 1)
      ;;
    "Darwin")
      echo $(md5 -q "$FNAME")
      ;;
  esac
}

checkmd5() {
    local FNAME=$1
    if [[ ! -f $FNAME ]]; then
        error "$FNAME is not a file"
        return 1
    fi
    local EXPECTED=$2
    local ACTUAL=$(md5str "$FNAME")
    if [ $EXPECTED = $ACTUAL ]; then
        info "$FNAME: successfully checked"
        return 0
    else
        error "$FNAME md5sum did not match."
        error "Expected: $EXPECTED"
        error "Actual: $ACTUAL"
        mv ${FNAME} ${FNAME}.old && warn "$FNAME is removed"
        return 1
    fi
}

timeit() {
    local start=$(date +%s.%N)
    $@
    local elapsed=$(echo "$(date +%s.%N)-$start" | bc)
    info "Time used $elapsed"
}

echo_installed_deb_package() {
    for pkg in $@; do
        local s=$(dpkg-query -W -f='${db:Status-Abbrev}=${Version}' "$pkg" 2>/dev/null)
        local ver=${s##*=}
        if [[ ${s:1:1} == 'i' ]]; then
            echo "$pkg"
        fi
    done
}

get_installed_deb_package_version() {
    local pkg=$1
    local s=$(dpkg-query -W -f='${db:Status-Abbrev}=${Version}' "$pkg")
    local ver=${s##*=}
    if [[ ${s:1:1} == 'i' ]]; then
        echo "$pkg==$ver"
    fi
}

check_apt_installed() {
    # Check if the given debian packages are installed
    local pkgs=$@
    local s
    local v
    local ver
    local pkg
    for pkg in $pkgs; do
        if [[ ${pkg} =~ .*"=".* ]]; then
            ver=${pkg##*=}
            pkg=${pkg%=*}
            s=$(dpkg-query -W -f='${db:Status-Abbrev}=${Version}' "$pkg")
            v=${s##*=}
            s=${s%=*}
            if [[ $ver != $v || ${#s} != 3 || ${s:1:1} != 'i' ]]; then
                return 1
            else
                info "$pkg=$ver is already installed"
            fi
        else
            s=$(dpkg-query -W -f='${db:Status-Abbrev}' "$pkg")
            if [[ ${#s} != 3 || ${s:1:1} != 'i' ]]; then
                return 1
            else
                info "$pkg is already installed"
            fi
        fi
    done
}

apt_get_install() {
    echo $@ >> ~/.hr/apt-get-requirements.txt
    if ! check_apt_installed "$@"; then
        $SUDO apt-get ${APT_GET_OPTS} install "$@" || (
            $SUDO apt-get ${APT_GET_OPTS} update &&
            $SUDO apt-get ${APT_GET_OPTS} install "$@")
    fi
}

pip2_install() {
    echo $@ >> ~/.hr/pip2_requirements.txt
    $PIP2 install $@
}

pip3_install() {
    echo $@ >> ~/.hr/pip3_requirements.txt
    $PIP3 install $@
}

add_ppa() {
    user=$(echo $1|cut -d: -f2|cut -d/ -f1)
    ppa=$(echo $1|cut -d: -f2|cut -d/ -f2)
    for file in `find /etc/apt/ -name \*.list`; do
        set +e
        item=$(grep -o "^deb http://ppa.launchpad.net/[a-z0-9\-]\+/[a-z0-9\-]\+" $file)
        set -e
        USER=`echo $item | cut -d/ -f4`
        PPA=`echo $item | cut -d/ -f5`
        if [[ $USER == $user && $PPA == $ppa ]]; then
            info "PPA $1 is already added"
            return 0
        fi
    done
    info $SUDO add-apt-repository -y $1
    $SUDO add-apt-repository -y $1
}

curl_cache() {
    url=$1
    ofile=${2-${url##*/}}
    info "Downloading $(basename $1)"
    [[ -f ${HR_CACHE}/${ofile} ]] || curl -L ${url} -o ${HR_CACHE}/${ofile} || rm ${HR_CACHE}/${ofile}

    # check md5sum
    local sum=${MD5SUMS[$ofile]}
    local retry=1
    if [[ ! -z $sum ]]; then
        while (( $retry >= 0 )); do
            if checkmd5 ${HR_CACHE}/${ofile} $sum; then
                break
            fi
            retry=$((retry-1))
            echo $retry
            if (( $retry >= 0 )); then
                curl -L ${url} -o ${HR_CACHE}/${ofile}
            fi
        done
    fi

    if [[ -f ${HR_CACHE}/${ofile} ]]; then
        info "Downloading $(basename $1) is done"
    fi
}

wget_cache() {
    url=$1
    ofile=${2-${url##*/}}
    info "Downloading $(basename $1)"
    [[ -f ${HR_CACHE}/${ofile} ]] || wget ${url} -O ${HR_CACHE}/${ofile} || rm ${HR_CACHE}/${ofile}

    # check md5sum
    local sum=${MD5SUMS[$ofile]}
    local retry=1
    if [[ ! -z $sum ]]; then
        while (( $retry >= 0 )); do
            if checkmd5 ${HR_CACHE}/${ofile} $sum; then
                break
            fi
            retry=$((retry-1))
            echo $retry
            if (( $retry >= 0 )); then
                wget ${url} -O ${HR_CACHE}/${ofile}
            fi
        done
    fi

    if [[ -f ${HR_CACHE}/${ofile} ]]; then
        info "Downloading $(basename $1) is done"
    fi
}

_get_confirm() {
    local message="${1:-Are you sure?}"
    local answer
    if [ "$ASSUME_YES" -eq 1 ] ; then
        confirm=1
        return
    fi
    printf "$message"
    read -r answer
    ! printf '%s\n' "$answer" | grep -Eq "$(locale yesexpr)"
    confirm=$?
}

clone() {
    owner=$1
    repo=$2
    dest=${3-"."}/$repo
    # if ssh clone failed, then try https clone
    if [[ -d $dest ]]; then
        info "$dest already exists"
    else
        info "Cloning $repo"
        git clone git@github.com:$owner/$repo.git $dest || git clone https://github.com/$owner/$repo.git $dest
        info "Cloning $repo is done"
    fi
}

_list_robots() {
    for f in $(find $1 -name config.yaml); do
        if grep "botname" $f>/dev/null; then
            echo $f | awk -F/ '{print $(NF-1)}'
        fi
    done
}

list_robots() {
    read_workspace
    _list_robots $HR_WORKSPACE/HEAD/src/robots_config
}

list_installed() {
    echo_installed_deb_package ${HEAD_PACKAGES[@]}
}

list_components() {
    if [[ $1 == 'cmd' ]]; then
        local funcs=$(compgen -A function)
        for f in ${funcs[@]}; do
            echo ${f}
        done
    else
        local funcs=$(compgen -A function|grep -E "^${1}_.*")
        for f in ${funcs[@]}; do
            echo ${f#${1}_};
        done
    fi
}

validate_component_args() {
    if [[ $# == 1 ]]; then
        eval help_${1}
        return 0
    fi
    local found_components=$(list_components $1)

    shift
    for arg in $@; do
        local found=0
        for f in $found_components; do
            if [[ $f == $arg ]]; then
                found=1
            fi
        done
        if [[ $found == 0 ]]; then
            error "Invalid argument $arg"
            return 1
        fi
    done
    return 0
}

check_or_create_ws() {
    [[ ! -z $1 ]]
    if [[ ! -d $1 ]]; then
        local confirm
        _get_confirm "The workspace ${1} does not exist, create? [y/N]"
        if [[ ${confirm} -eq 1 ]]; then
            mkdir -p ${1}
            info "Workspace directory ${1} is created"
        fi
    fi
}

set_workspace() {
    local new_hr_workspace=${1:-$DEFAULT_HR_WORKSPACE}
    read_workspace >/dev/null || true
    if [[ ! "$new_hr_workspace" = /* ]]; then
        new_hr_workspace=$(pwd)/$new_hr_workspace
    fi
    if [[ $new_hr_workspace != '/' ]]; then
        new_hr_workspace=${new_hr_workspace%/}
    fi
    if [[ ! -z ${HR_WORKSPACE} && ${HR_WORKSPACE} != ${new_hr_workspace} ]]; then
        local confirm
        _get_confirm "The workspace is already set to ${COLOR_INFO}${HR_WORKSPACE}${COLOR_RESET}. Do you want to set to ${COLOR_WARN}${new_hr_workspace}${COLOR_RESET}? [y/N]"
        if [[ ${confirm} != 1 ]]; then
            return
        fi
    fi
    check_or_create_ws $new_hr_workspace
    if [[ ! -d $new_hr_workspace ]]; then
        error "HR workspace is incorrect"
        exit 1;
    fi
    if [[ ! -d $(dirname $HR_ENVFILE_PATH) ]]; then mkdir -p $(dirname $HR_ENVFILE_PATH); fi
    export HR_WORKSPACE=$new_hr_workspace
}

read_workspace() {
    if [[ -f $HR_ENVFILE_PATH ]]; then
        local str=$(cat $HR_ENVFILE_PATH|grep "export HR_WORKSPACE=")
        if [[ -z $str ]]; then
            error "HR_WORKSPACE is not found in ${HR_ENVFILE_PATH}. Please re-run \"hr init\""
            return 1
        else
            HR_WORKSPACE=${str#export HR_WORKSPACE=}
        fi
        if [[ ! -d $HR_WORKSPACE ]]; then
            error "HR_WORKSPACE ${HR_WORKSPACE} doesn't exist."
            return 1
        else
            export HR_WORKSPACE=$HR_WORKSPACE
        fi
    else
        return 1
    fi
}

print_repo_info() {
    read_workspace >/dev/null
    local lg='git log -1 --no-merges --abbrev-commit --decorate --date=relative'
    local commit='--format=format:"%C(bold blue)%h%C(reset) %C(white)%<(50,trunc)%s%C(reset) %C(dim white)- %<(20,trunc)%an%C(reset) %C(bold green)%<(20,trunc)%ar%C(reset)"'
    local format="%-32s %-15s %s"
    printf "${format}\n" "Repository" "Branch" "Commit"
    for repo in ${HR_REPOS[*]}
    do
        if [[ -d $HR_WORKSPACE/$repo ]]; then
            cd $HR_WORKSPACE/$repo
            branch=$(git rev-parse --abbrev-ref HEAD)
            printf "${format}\n" "$repo" "$branch" "$(eval $lg $commit)"
        fi
    done
    for repo in ${OPENCOG_REPOS[*]}
    do
        if [[ -d $HR_WORKSPACE/opencog/$repo ]]; then
            cd $HR_WORKSPACE/opencog/$repo
            branch=$(git rev-parse --abbrev-ref HEAD)
            printf "${format}\n" "opencog/$repo" "$branch" "$(eval $lg $commit)"
        fi
    done
    echo ''
}

remove_installed_files() {
    local installed_file=$1
    if [[ -f $installed_file ]]; then
        local files=$(sort -u $installed_file)
        if [[ $ASSUME_YES == 0 ]]; then
            for f in $files; do
                echo "> $f"
            done
            local confirm
            _get_confirm "These files will be removed [y/N] "
            if [[ ${confirm} != 1 ]]; then
                exit
            fi
        fi
        for f in $files; do
            if [[ -e $f || -L $f ]]; then
                $SUDO rm $f
                info "Removed $f"
            fi
        done
        rm $installed_file
    else
        info "Nothing to remove"
    fi
}

get_release_versions() {
    local url=$1
    if [[ ! -z ${url} ]]; then
        curl -s ${url%/} | jq -r '.[] | select(.prerelease == false) | .tag_name'
    fi
}

get_latest_version() {
    local url=$1
    if [[ ! -z ${url} ]]; then
        curl -s "${url%/}/latest" | jq -r 'select(.prerelease == false) | .tag_name'
    fi
}
############# End of Common #############

############# Entries #############
hr_install() {
    validate_component_args install $@
    for arg in $@; do
        local func=install_${arg}
        info "Installing ${arg}"
        eval $func
        if [[ $? != 0 ]]; then
            error "Install ${arg} failed return code $?"
        fi
    done
}

hr_uninstall() {
    validate_component_args uninstall $@
    for arg in $@; do
        local func=uninstall_${arg}
        info "Uninstalling ${arg}"
        eval $func
        if [[ $? != 0 ]]; then
            error "Uninstall ${arg} failed return code $?"
        fi
    done
}

hr_update() {
    validate_component_args update $@
    for arg in $@; do
        local func=update_${arg}
        eval $func
    done
}

hr_build() {
    validate_component_args build $@
    for arg in $@; do
        local func=build_${arg}
        eval $func
    done
}

hr_get() {
    validate_component_args get $@
    for arg in $@; do
        local func=get_${arg}
        info "Getting ${arg}"
        eval $func
        info "${arg} is got"
    done
}

hr_clean() {
    validate_component_args clean $@
    for arg in $@; do
        local func=clean_${arg}
        info "Cleaning up ${arg}"
        eval $func
        info "${arg} is cleaned up"
    done
}

hr_cmd() {
    local func=$1
    shift
    $func $@
}

hr_init() {
    set_workspace $@
    echo export HR_WORKSPACE=$HR_WORKSPACE > $HR_ENVFILE_PATH
cat <<EOF >>$HR_ENVFILE_PATH
export HR_PREFIX=$HR_PREFIX
export HR_CACHE=$HR_CACHE

export ROS_PKG_PREFIX=$ROS_PKG_PREFIX
export VISION_TOOL_PREFIX=$VISION_TOOL_PREFIX
export DLIB_DIR=$DLIB_DIR
export TORCH_DIR=$TORCH_DIR
export OPENFACE_DIR=$OPENFACE_DIR
export CPPMT_DIR=$CPPMT_DIR
export EMOTIME_DIR=$EMOTIME_DIR

export MARKY_MARKOV_DIR=$MARKY_MARKOV_DIR
export HR_MODELS=$HR_MODELS

export ROS_LOG_DIR="$HOME/.hr/log"
export PYTHONPATH=\$PYTHONPATH:$OPENFACE_DIR:$DLIB_DIR/dlib-${DLIB_VERSION}/dist:/usr/local/share/opencog/python

export LD_LIBRARY_PATH=$LD_LIBRARY_PATH
export LIBRARY_PATH=$LIBRARY_PATH
export DLIB_PATH=$DLIB_PATH
export CPLUS_INCLUDE_PATH=$CPLUS_INCLUDE_PATH
export MANYEARSLIB_PREFIX=$MANYEARSLIB_PREFIX

export CLANDMARK_DIR=$VISION_TOOL_PREFIX/clandmark
export OpenBR_DIR=$OpenBR_DIR

if [[ -f $TORCH_DIR/install/bin/torch-activate ]]; then
  source $TORCH_DIR/install/bin/torch-activate
fi

if [[ -f $ROS_PKG_PREFIX/setup.bash ]]; then
  source $ROS_PKG_PREFIX/setup.bash
fi
EOF
    info HR_WORKSPACE=$HR_WORKSPACE
}

hr_env() {
    if [[ -f $HR_ENVFILE_PATH ]]; then
        cat $HR_ENVFILE_PATH
    else
        error "Please run \"hr init\""
    fi
}

hr_version() {
    for pkg in ${HEAD_PACKAGES[@]}; do
        get_installed_deb_package_version ${pkg} 2>/dev/null
    done
    echo ''
    print_repo_info
}

hr_run() {
    read_workspace
    cd $HR_WORKSPACE/HEAD/scripts
    ./main.sh --autoname --autobody --nogui $@
}

hr_stop() {
    read_workspace
    cd $HR_WORKSPACE/HEAD/scripts
    ./stop.sh
}

############# End of Entries #############

############# Functions #############
install_head() {
    install_head-deps
    get_head
    build_head
}

install_head-deps() {
    setup_venv
    _install_basic
    _install_ros
    _install_blender
    _install_webui_deps
    _install_marky_markov
    _install_scipy_stack
    _install_pocketsphinx
    _install_festival_tts
    _install_misc

    wget_cache https://raw.githubusercontent.com/hansonrobotics/HEAD/master/scripts/patch/rosbridge.patch
    $SUDO patch -N /opt/ros/indigo/lib/python2.7/dist-packages/rosbridge_library/internal/publishers.py ${HR_CACHE}/rosbridge.patch || true
}

_install_basic() {
    local pkgs=(git wget telnet python3-pip python-pip build-essential
            software-properties-common bc)
    apt_get_install "${pkgs[@]}"
}

setup_venv() {
    $SUDO pip2 install virtualenv
    virtualenv --system-site-packages -p /usr/bin/python2 $HR_PY2_VIRTUALENV
    virtualenv --system-site-packages -p /usr/bin/python3 $HR_PY3_VIRTUALENV
}

_install_ros() {
    $SUDO sh -c 'echo "deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main" > /etc/apt/sources.list.d/ros-latest.list'
    $SUDO apt-key adv --keyserver hkp://ha.pool.sks-keyservers.net --recv-key 0xB01FA116
    local pkgs=(
        ros-indigo-desktop
        ros-indigo-tf
        ros-indigo-driver-common
        ros-indigo-cv-bridge
        ros-indigo-image-transport
        ros-indigo-openni-camera
        ros-indigo-mjpeg-server
        ros-indigo-usb-cam
        ros-indigo-dynamixel-motor
        ros-indigo-robot-state-publisher
        ros-indigo-joint-state-publisher
        ros-indigo-rosbridge-server
        python-catkin-tools
    )

    # for camera calibration
    pkgs+=(ros-indigo-image-proc)

    apt_get_install "${pkgs[@]}"

    # for blender to find ros packages
    pip3_install rospkg catkin_pkg

    if [[ ! -f /etc/ros/rosdep/sources.list.d/20-default.list ]]; then
        $SUDO rosdep init -q
        rosdep update -q
    fi
}

install_opencog() {
    install_opencog-deps
    get_opencog
    build_opencog
}

install_opencog-deps() {
    local pkgs=(
        cmake ccache
        binutils-dev
        libboost-dev libboost-date-time-dev libboost-filesystem-dev
        libboost-program-options-dev libboost-regex-dev
        libboost-serialization-dev libboost-system-dev libboost-thread-dev
        guile-2.0-dev cython
    )
    apt_get_install "${pkgs[@]}"

    wget http://raw.github.com/opencog/ocpkg/master/ocpkg -qO octool
    chmod +rx octool
    ./octool -dpv
    rm octool

    # For sentiment analysis
    _install_nltk

    _install_relex_deps
}

_install_nltk() {
    pip2_install nltk
    $PYTHON2 -m nltk.downloader -d /usr/local/share/nltk_data punkt averaged_perceptron_tagger
}

_install_marky_markov() {
    if [ ! -d $MARKY_MARKOV_DIR ]; then
      git clone https://github.com/hansonrobotics/marky_markov.git $MARKY_MARKOV_DIR
    else
      warn "Skipping marky_markov clone"
    fi
    MD5SUMS["markov_modeling.tar.gz"]=7d51bbcd4df89b2633bd9520fb99b2b7
    wget_cache $GITHUB_STORAGE_URL/markov_modeling.tar.gz
    tar zxf ${HR_CACHE}/markov_modeling.tar.gz -C $HR_MODELS

    add_ppa ppa:brightbox/ruby-ng
    apt_get_install ruby2.3 ruby2.3-dev
    $SUDO gem install marky_markov
}

_install_link_grammar() {
    MD5SUMS["link-grammar-5.3.13.tar.gz"]=d519ff9f404bbda5bfe229839272d91c
    wget_cache $GITHUB_STORAGE_URL/link-grammar-5.3.13.tar.gz

    $SUDO rm -rf /tmp/link-grammar-5.3.13
    tar -zxf ${HR_CACHE}/link-grammar-5.3.13.tar.gz -C /tmp
    mkdir -p /tmp/link-grammar-5.3.13/build
    cd /tmp/link-grammar-5.3.13/build
    JAVA_HOME=/usr/lib/jvm/default-java
    ../configure
    make -j$(nproc)
    $SUDO make install
    $SUDO ldconfig
    $SUDO rm -rf /tmp/link-grammar-5.3.13
    cd $BASEDIR
}

_install_relex_deps() {
    local pkgs=(
        build-essential python-dev swig zlib1g-dev unzip wget
        wordnet-dev wordnet-sense-index
        openjdk-7-jdk
        ant libcommons-logging-java libgetopt-java
    )
    apt_get_install "${pkgs[@]}"

    if [[ ! -e /usr/local/lib/liblink-grammar.so ]]; then
        _install_link_grammar
    fi

    # Java WordNet Library
    if [[ ! -e /usr/local/share/java/jwnl.jar ]]; then
        MD5SUMS["jwnl14-rc2.zip"]=c1c35ce1d1590938abe48d7785f87ae0
        wget_cache $GITHUB_STORAGE_URL/jwnl14-rc2.zip
        unzip -qo ${HR_CACHE}/jwnl14-rc2.zip -d /tmp jwnl14-rc2/jwnl.jar
        $SUDO mv -v /tmp/jwnl14-rc2/jwnl.jar /usr/local/share/java/
        $SUDO rm -r /tmp/jwnl14-rc2
        $SUDO chmod -v 0644 /usr/local/share/java/jwnl.jar
    fi
}

_install_pocketsphinx() {
    if [[ -f /opt/hansonrobotics/lib/pkgconfig/pocketsphinx.pc && -f /opt/hansonrobotics/lib/pkgconfig/sphinxbase.pc ]]; then
        info "Pocketsphinx is already installed."
        return
    fi
    apt_get_install bison automake libtool
    MD5SUMS["sphinxbase-1.0.0.tar.gz"]=df69f72b19abd943cfc4b51ec30a3b29
    MD5SUMS["pocketsphinx-1.0.0.tar.gz"]=b94bf391c22b6dd4c86a8c112aa62f48
    wget_cache https://github.com/hansonrobotics/sphinxbase/archive/v1.0.0.tar.gz sphinxbase-1.0.0.tar.gz
    wget_cache https://github.com/hansonrobotics/pocketsphinx/archive/v1.0.0.tar.gz pocketsphinx-1.0.0.tar.gz

    tar zxf ${HR_CACHE}/sphinxbase-1.0.0.tar.gz -C /tmp
    cd /tmp/sphinxbase-1.0.0
    ./autogen.sh && ./configure --prefix=$HR_PREFIX && make && $SUDO make install
    $SUDO rm -r /tmp/sphinxbase-1.0.0

    tar zxf ${HR_CACHE}/pocketsphinx-1.0.0.tar.gz -C /tmp
    cd /tmp/pocketsphinx-1.0.0
    ./autogen.sh && ./configure --prefix=$HR_PREFIX && make && $SUDO make install
    $SUDO rm -r /tmp/pocketsphinx-1.0.0
    cd $BASEDIR
}

_install_blender() {
    add_ppa ppa:irie/blender
    apt_get_install blender
}

_install_ffmpeg() {
    # For blender_api_test
    add_ppa ppa:mc3man/trusty-media
    apt_get_install ffmpeg
}

_install_festival_tts() {
    # For Festival
    apt_get_install festival festival-dev

    # Install female voice
    if [[ ! -f ~/.hr/tts/festival/voices/festvox_cmu_us_slt_arctic_hts.tar.gz ]]; then
        MD5SUMS["festvox_cmu_us_slt_arctic_hts.tar.gz"]=a9b53441968f6bc612b85c04bbc4cf0f
        wget_cache http://festvox.org/packed/festival/2.1/festvox_cmu_us_slt_arctic_hts.tar.gz
    fi
    tar zxf ${HR_CACHE}/festvox_cmu_us_slt_arctic_hts.tar.gz -C /tmp
    $SUDO cp -rT /tmp/festival/lib/voices /usr/share/festival/voices
    rm -rf /tmp/festival
}

_install_marytts() {
    mkdir -p ~/.hr/tts/marytts
    MD5SUMS["marytts-5.1.2.zip"]=99e774dd4c6e791ad916ae76351522f0
    wget_cache https://github.com/marytts/marytts/releases/download/v5.1.2/marytts-5.1.2.zip
    unzip -qod ~/.hr/tts/marytts ${HR_CACHE}/marytts-5.1.2.zip
}

_install_misc() {
    local pkgs=()

    # For rosbridge_server
    pkgs+=(python-bson)

    # For pololu-motors
    # DO NOT UPGRADE WITH PIP
    pkgs+=(python-serial)

    # For Blender
    pkgs+=(python3-numpy)

    # For running scripts
    pkgs+=(tmux)

    # For tts playing audio
    pkgs+=(python-pyglet)

    # For chatbot
    pkgs+=(python-yaml)

    # Swig for iflytek SDK
    pkgs+=(swig)

    # For rospy to run with python3
    pkgs+=(python3-yaml)

    # For telnet automation
    pkgs+=(expect)

    # For audio recording
    pkgs+=(pulseaudio python-pyaudio)

    # For window layout
    pkgs+=(xdotool)

    apt_get_install "${pkgs[@]}"

    # For chatbot
    pip2_install num2words

    # For Chinese tts
    pip2_install pinyin==0.2.5

    # For speech2command
    pip2_install pyparsing

    # For performances
    pip2_install transitions

    # For webui
    pip2_install flask EasyProcess psutil natsort

    pip2_install https://github.com/hansonrobotics/pololu-motors/archive/v0.2.1.tar.gz --no-deps
}

_install_manyears_deps() {
    if [[ ! -e $MANYEARSLIB_PREFIX/bin/libmanyears.a ]]; then
        # FOR GUI to build $SUDO apt-get ${APT_GET_OPTS} install qtmobility-dev
        MD5SUMS["manyears.tar.gz"]=cf8688959e6d6a7ea9cdd1167814862a
        wget_cache https://github.com/hansonrobotics/manyears-C/archive/v1.0.0.tar.gz manyears.tar.gz
        mkdir -p $MANYEARSLIB_PREFIX
        tar zxf $HR_CACHE/manyears.tar.gz --strip-components 1 -C $MANYEARSLIB_PREFIX
        mkdir -p $MANYEARSLIB_PREFIX/build && cd $MANYEARSLIB_PREFIX/build && cmake .. && make
        $SUDO make install
        cp install_manifest.txt  ~/.hr/manyears_deps_installed.txt
    else
        info "Manyears is already installed"
    fi
}

_install_test_deps() {
    apt_get_install socat

    # WebUI compatable webserver
    $SUDO npm install xmlhttprequest --prefix $HR_WORKSPACE/$PROJECT/src/chatbot/scripts

    # for python test coverage
    $SUDO pip install coverage
}

_install_webui_deps() {
    # Remove npm and nodejs if needed
    # sudo npm uninstall -g npm
    # sudo apt-get remove nodejs

    # See https://github.com/nodesource/distributions#debinstall
    if ! hash nodejs; then
        info "Installing nodejs"
        curl -sL https://deb.nodesource.com/setup_6.x | sudo -E bash -
        apt_get_install nodejs
        info "Installing nodejs done"
    fi
    if ! npm ls -g webpack >/dev/null; then
        $SUDO npm install -g webpack
    fi
    if ! npm ls -g nodemon >/dev/null; then
        $SUDO npm install -g nodemon
    fi
}

_install_scipy_stack() {
    apt_get_install libblas-dev liblapack-dev libatlas-base-dev gfortran
    pip2_install numpy pandas scipy
}

_install_opencv() {
    if [[ ! -f ${HR_PREFIX}/lib/libopencv_core.so ]]; then
        MD5SUMS["opencv-2.4.11.zip"]=32f498451bff1817a60e1aabc2939575
        wget_cache https://downloads.sourceforge.net/project/opencvlibrary/opencv-unix/2.4.11/opencv-2.4.11.zip
        $SUDO rm -rf /tmp/opencv-2.4.11
        unzip ${HR_CACHE}/opencv-2.4.11.zip -d /tmp
        cd /tmp/opencv-2.4.11
        mkdir build
        cd build
        cmake -DWITH_FFMPEG=OFF -DWITH_CUDA=OFF -DWITH_OPENCL=OFF -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=${HR_PREFIX} .. && make -j4
        $SUDO make install
        cp install_manifest.txt  ~/.hr/opencv_installed.txt
        $SUDO rm -rf /tmp/opencv-2.4.11
        cd ${HR_WORKSPACE}
    fi
}

_install_openbiometrics() {
    apt_get_install --force-yes qt5-default libqt5svg5-dev
    _install_opencv
    if [[ ! -f ${HR_PREFIX}/lib/libopenbr.so ]]; then
        if [ ! -d ${OPENBR_SRC_DIR} ]; then
            info "Cloning openbr"
            git clone https://github.com/biometrics/openbr.git ${OPENBR_SRC_DIR}
        fi
        cd ${OPENBR_SRC_DIR}
        git checkout v1.1.0
        git submodule init
        git submodule update

        mkdir -p ${OPENBR_SRC_DIR}/build
        cd ${OPENBR_SRC_DIR}/build
        cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=${HR_PREFIX} .. && make -j4
        $SUDO make install
        cp install_manifest.txt  ~/.hr/openbiometrics_installed.txt
        cd ${HR_WORKSPACE}
    fi
}

_install_dlib() {
    if [[ ! -e $DLIB_PATH/dist/dlib/dlib.so ]]; then
      # The dlib DNS server sometimes times out. Pinging it first
      # makes it much more likely that the wget will succeed.
      ping -c 5 dlib.net
      MD5SUMS["dlib-${DLIB_VERSION}.tar.bz2"]=da930a35c2aa88612dd2ebf893f48f60
      wget_cache http://dlib.net/files/dlib-${DLIB_VERSION}.tar.bz2
      mkdir -p $DLIB_PATH
      tar -xf $HR_CACHE/dlib-${DLIB_VERSION}.tar.bz2 -C $DLIB_DIR
      cd $DLIB_PATH && python setup.py build
    else
      warn "Skipping dlib installation"
    fi
}

_install_clandmarks() {
    # Install clandmarks
    if [ ! -d $CLANDMARK_DIR ]; then
      MD5SUMS["clandmark.tar.bz2"]=0d1eb90bad2c02fb38aed4e464555f02
      wget_cache $GITHUB_STORAGE_URL/clandmark.tar.bz2
      mkdir -p $CLANDMARK_DIR
      tar -xf $HR_CACHE/clandmark.tar.bz2 -C $CLANDMARK_DIR --strip-components=1
    else
      warn "Skipping clandmark downloading"
    fi
}

_install_torch() {
    if [ ! -d $TORCH_DIR ]; then
        git clone https://github.com/torch/distro.git $TORCH_DIR --recursive

        cd $TORCH_DIR
        bash install-deps
        echo no | ./install.sh

        # Install lua packages in the torch file in scripts directory.
        info "Installing lua packages"
        cd $TORCH_DIR/install/bin
        ./luarocks install nn
        ./luarocks install dpnn
        ./luarocks install image
        ./luarocks install optim
        ./luarocks install csvigo
        ./luarocks install sys
        info "Installing lua packages is done"
        cd $BASEDIR
    else
        warn "Skipping Torch installation"
    fi
}

_install_openface() {
    # This is to install scikit-images as the pip version requires cython0.23 which can't be installed otherwise.
    apt_get_install python-skimage
    pip2_install numpy pandas scipy scikit-learn

    if [ ! -d $OPENFACE_DIR ]; then
      info "Cloning openface"
      git clone https://github.com/hansonrobotics/openface.git $OPENFACE_DIR --recursive
    else
      warn "Skipping openface clone"
    fi

    # $OPENFACE_DIR/models/get-models.sh
    MD5SUMS["nn4.small2.v1.t7"]=c95bfd8cc1adf05210e979ff623013b6
    MD5SUMS["celeb-classifier.nn4.small2.v1.pkl"]=199a2c0d32fd0f22f14ad2d248280475
    MD5SUMS["shape_predictor_68_face_landmarks.dat.bz2"]=677a91476056de0507f1915adc7ef86a
    wget_cache http://openface-models.storage.cmusatyalab.org/nn4.small2.v1.t7
    wget_cache http://openface-models.storage.cmusatyalab.org/celeb-classifier.nn4.small2.v1.pkl
    if [[ ! -f ${HR_CACHE}/shape_predictor_68_face_landmarks.dat ]]; then
        wget_cache http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2
        bunzip2 -f ${HR_CACHE}/shape_predictor_68_face_landmarks.dat.bz2
    fi
    checkmd5 ${HR_CACHE}/celeb-classifier.nn4.small2.v1.pkl 199a2c0d32fd0f22f14ad2d248280475
    mkdir -p $OPENFACE_DIR/models/dlib
    mkdir -p $OPENFACE_DIR/models/openface
    cp ${HR_CACHE}/shape_predictor_68_face_landmarks.dat ${OPENFACE_DIR}/models/dlib
    cp ${HR_CACHE}/nn4.small2.v1.t7 ${OPENFACE_DIR}/models/openface
    cp ${HR_CACHE}/celeb-classifier.nn4.small2.v1.pkl ${OPENFACE_DIR}/models/openface
}

_install_cmt() {
    if [ ! -d $CPPMT_DIR ]; then
        info "Cloning CppMT"
        git clone https://github.com/hansonrobotics/CppMT.git $CPPMT_DIR
        cd $CPPMT_DIR
        git checkout wrapper
    else
        warn "Skipping CppMT clone"
    fi

    if [ ! -f $CPPMT_DIR/cmt ]; then
        cd $CPPMT_DIR
        cmake .
        make -j$(nproc)
    fi
    cd $BASEDIR
}

_install_emotime() {
    if [ ! -d $EMOTIME_DIR ]; then
      info "Cloning emotime"
      git clone https://github.com/hansonrobotics/emotime.git $EMOTIME_DIR
    else
      warn "Skipping emotime clone"
    fi
    cd $EMOTIME_DIR/build
    cmake ..
    make -j$(nproc)
}

_install_vision_deps() {
    mkdir -p $VISION_TOOL_PREFIX
    apt_get_install libopencv-dev ros-indigo-opencv-apps

    # Tkinter error other wise.
    pip2_install -I Pillow
    pip2_install imgurpython

    _install_dlib
    _install_clandmarks
    _install_torch
    _install_openface
    _install_cmt
    _install_emotime
    _install_openbiometrics
}

_install_calib_tools() {
    MD5SUMS["maestro-linux-150116.tar.gz"]=84feed740c0695bb0eea13ccf7988b97
    wget_cache $GITHUB_STORAGE_URL/maestro-linux-150116.tar.gz
    mkdir -p ${HR_PREFIX}/maestro
    tar zxf ${HR_CACHE}/maestro-linux-150116.tar.gz -C ${HR_PREFIX}/maestro --strip-components 1
    apt_get_install libusb-1.0-0-dev mono-runtime libmono-winforms2.0-cil
    $SUDO cp ${HR_PREFIX}/maestro/99-pololu.rules /etc/udev/rules.d/
    #$SUDO udevadm control --reload-rules

    MD5SUMS["mx_calib"]=5e34a64564df92c116f027a9ff48a11b
    wget_cache $GITHUB_STORAGE_URL/mx_calib
    if [[ ! -f ${HR_PREFIX}/bin/mx_calib ]]; then
        $SUDO cp ${HR_CACHE}/mx_calib ${HR_PREFIX}/bin
        $SUDO chmod +x ${HR_PREFIX}/bin/mx_calib
    fi
}

_install_deb_packages() {
    [[ -f ${HR_CACHE}/${debname} ]] && rm ${HR_CACHE}/${debname}
    if [[ -z ${url} || -z $debname ]]; then
        error "requires url and debname variables"
        return 1
    fi
    curl_cache ${url} ${debname}
    $SUDO dpkg -i "${HR_CACHE}/${debname}" || $SUDO apt-get install -f
    [[ -f ${HR_CACHE}/${debname} ]] && rm ${HR_CACHE}/${debname}
}

install_head-hr-ext() {
    local version=0.1.2
    local debname=head-hr-ext_${version}_amd64.deb
    local url=${GITHUB_STORAGE2_URL}/$debname
    _install_deb_packages
}

install_head-hr-msgs() {
    local version=$(get_latest_version https://api.github.com/repos/hansonrobotics/hr_msgs/releases)
    local debname=head-hr_msgs_${version#v}_amd64.deb
    local url=https://github.com/hansonrobotics/hr_msgs/releases/download/${version}/${debname}
    _install_deb_packages
}

install_head-saliency-tracker() {
    local version=$(get_latest_version https://api.github.com/repos/hansonrobotics/ros_nmpt_saliency/releases)
    local debname=head-saliency-tracker_${version#v}_amd64.deb
    local url=https://github.com/hansonrobotics/ros_nmpt_saliency/releases/download/${version}/$debname
    _install_deb_packages
}

install_head-chatbot() {
    local version=$(get_latest_version https://api.github.com/repos/hansonrobotics/chatbot/releases)
    local debname=head-chatbot_${version#v}_amd64.deb
    local url=https://github.com/hansonrobotics/chatbot/releases/download/${version}/$debname
    _install_deb_packages
}

install_head-motor-control() {
    local version=$(get_latest_version https://api.github.com/repos/hansonrobotics/motor_control/releases)
    local debname=head-motor-control_${version#v}_amd64.deb
    local url=https://github.com/hansonrobotics/motor_control/releases/download/${version}/$debname
    _install_deb_packages
}

install_head-python-pololu-motors() {
    local version=$(get_latest_version https://api.github.com/repos/hansonrobotics/pololu-motors/releases)
    local debname=head-python-pololu-motors_${version#v}_all.deb
    local url=https://github.com/hansonrobotics/pololu-motors/releases/download/${version}/$debname
    _install_deb_packages
}

install_head-sound() {
    local version=$(get_latest_version https://api.github.com/repos/hansonrobotics/sound/releases)
    local debname=head-sound_${version#v}_amd64.deb
    local url=https://github.com/hansonrobotics/sound/releases/download/${version}/$debname
    _install_deb_packages
}

install_head-python-ttsserver() {
    local version=$(get_latest_version https://api.github.com/repos/hansonrobotics/ttsserver/releases)
    local debname=head-python-ttsserver_${version#v}_all.deb
    local url=https://github.com/hansonrobotics/ttsserver/releases/download/${version}/$debname
    _install_deb_packages
}

install_head-all() {
    local version=0.1.0
    local debname=head-all_${version}_amd64.deb
    local url=https://github.com/hansonrobotics/binary_dependency/raw/master/$debname

    setup_venv
    # setup ROS repository
    $SUDO sh -c 'echo "deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main" > /etc/apt/sources.list.d/ros-latest.list'
    $SUDO apt-key adv --keyserver hkp://ha.pool.sks-keyservers.net --recv-key 0xB01FA116
    # setup nodejs repository
    curl -sL https://deb.nodesource.com/setup_6.x | sudo -E bash -
    # setup python2.6 repository
    add_ppa ppa:fkrull/deadsnakes
    # setup ruby2.3
    add_ppa ppa:brightbox/ruby-ng

    _install_deb_packages
}


help_install() {
cat << EOF
hr install <dependency> [<dependency>] ...

Install dependencies

    all                     Install HEAD and its depencencies, OpenCog and its dependencies
    head                    Install HEAD and its depencencies
    opencog                 Install OpenCog and its dependencies
    head-deps               Install HEAD dependencies
    opencog-deps            Install OpenCog dependencies
    head-hr-msgs            Install hr_msgs, a shared set of ROS messages for HR
    head-hr-ext             Install hr tool extension
    head-chatbot            Install chatbot
    head-saliency-tracker   Install saliency tracker
EOF
}

uninstall_head-hr() {
    sudo apt-get remove head-hr
}

uninstall_head-hr-ext() {
    sudo apt-get remove head-hr-ext
}

uninstall_opencv() {
    remove_installed_files $HOME/.hr/opencv_installed.txt
    _remove_version opencv
}

uninstall_head-hr-msgs() {
    sudo apt-get remove head-hr-msgs
}

uninstall_head-chatbot() {
    sudo apt-get remove head-chatbot
}

uninstall_head-saliency-tracker() {
    sudo apt-get remove head-saliency-tracker
}

uninstall_head-motor-control() {
    sudo apt-get remove head-motor-control
}

uninstall_head-sound() {
    sudo apt-get remove head-sound
}

uninstall_head-python-ttsserver() {
    sudo apt-get remove head-python-ttsserver
}

help_uninstall() {
cat << EOF
hr uninstall <component> [<component>] ...

Uninstall components

    head-hr                 Uninstall hr tool
    head-hr-ext             Uninstall hr-ext
    head-hr-msgs            Uninstall hr_msgs
    head-chatbot            Uninstall chatbot
    head-saliency-tracker   Uninstall saliency tracker
    head-motor-control      Uninstall motor control
    head-sound              Uninstall sound tools
    head-python-ttsserver   Uninstall tts server
EOF
}

update_head() {
    read_workspace
    info "Updating HEAD source code"
    local DEFAULT_BRANCH="master"
    for repo in ${HR_REPOS[*]}
    do
        cd $HR_WORKSPACE/$repo
        branch=$(git rev-parse --abbrev-ref HEAD)
        if [[ $branch != $DEFAULT_BRANCH ]]; then
            warn "[${repo}] Branch is not (${DEFAULT_BRANCH}) branch (${branch}). Skip."
            continue
        fi
        info "Updating [${repo}]"
        git pull origin $DEFAULT_BRANCH
        info "Updating [${repo}] is done"
    done
    info "Updating HEAD source code is done"
}

update_opencog() {
    read_workspace
    info "Updating OpenCog source code"
    local DEFAULT_BRANCH="master"
    for repo in ${OPENCOG_REPOS[*]}
    do
        cd $HR_WORKSPACE/opencog/$repo
        branch=$(git rev-parse --abbrev-ref HEAD)
        if [[ $branch != $DEFAULT_BRANCH ]]; then
            warn "[${repo}] Branch is not (${DEFAULT_BRANCH}) branch (${branch}). Skip."
            continue
        fi
        info "Updating [${repo}]"
        git pull origin $DEFAULT_BRANCH
        info "Updating [${repo}] is done"
    done
    info "Updating OpenCog source code is done"
}

help_update() {
cat << EOF
hr update <component> [<component>] ...

Update components

    head        Update HEAD source code
    opencog     Update OpenCog source code
EOF
}

get_opencog() {
    read_workspace || hr_init
    info "Cloning OpenCog source code"
    for repo in ${OPENCOG_REPOS[*]}
    do
        cd $HR_WORKSPACE
        clone hansonrobotics $repo opencog
    done
    info "Cloning OpenCog source code is done"
}

get_head() {
    read_workspace || hr_init
    info "Cloning HR source code"
    for repo in ${HR_REPOS[*]}
    do
        cd $HR_WORKSPACE
        clone hansonrobotics $repo
    done
    info "Cloning HR source code is done"
}

get_models() {
    [[ ! -d $HR_MODELS ]] && mkdir -p $HR_MODELS
    local old_dir=${HOME}/.hr/cache/models
    if [[ -d ${old_dir} ]]; then
        for f in ${old_dir}/*; do
            [[ -f "$f" ]] || continue
            if [[ ! -e ${HR_MODELS}/${f##*/} ]]; then
                mv ${f} ${HR_MODELS}/
            fi
        done
    fi

    # openface
    wget_cache http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2
    wget_cache http://openface-models.storage.cmusatyalab.org/nn4.small2.v1.t7
    checkmd5 ${HR_CACHE}/shape_predictor_68_face_landmarks.dat.bz2 677a91476056de0507f1915adc7ef86a
    checkmd5 ${HR_CACHE}/nn4.small2.v1.t7 c95bfd8cc1adf05210e979ff623013b6
    cp ${HR_CACHE}/shape_predictor_68_face_landmarks.dat.bz2 ${HR_MODELS}
    bunzip2 -f ${HR_MODELS}/shape_predictor_68_face_landmarks.dat.bz2
    cp ${HR_CACHE}/nn4.small2.v1.t7 ${HR_MODELS}

    # markov
    wget_cache https://github.com/opencog/test-datasets/releases/download/current/markov_modeling.tar.gz
    checkmd5 ${HR_CACHE}/markov_modeling.tar.gz 7d51bbcd4df89b2633bd9520fb99b2b7
    mkdir -p $HR_MODELS/markov_modeling
    tar zxf ${HR_CACHE}/markov_modeling.tar.gz -C $HR_MODELS/markov_modeling
}

help_get() {
cat << EOF
hr get <component> [<component>] ...

Download components

    head        Download HEAD repositories
    opencog     Download OpenCog repositories
    models      Download models for dlib landmarks, markov text generator, etc.
    voices      Download TTS voices
EOF
}

_build_head() {
    read_workspace
    cd $HR_WORKSPACE/HEAD
    source /opt/ros/indigo/setup.bash
    if [[ ! -d .catkin_tools ]]; then
        catkin init
    fi

    if [[ $# > 0 ]]; then
        catkin config --blacklist $@
    fi
    catkin build --force-cmake -j$(nproc) --no-status --make-args install

    TARGET=$HR_WORKSPACE/HEAD/devel/lib/python2.7/dist-packages
    rm -rf $TARGET/roscom*
    info "Installing blender roscom"
    pip3 install -t $TARGET $HR_WORKSPACE/HEAD/src/blender_api_msgs --no-deps
}

build_head() {
    local blacklist=(
        audio_tools
        cmt_tracker
        cmt_tracker_msgs
        emotime
        eva_behavior
        eye_tracking
        face_id
        face_recognition
        manyears_msgs
        manyears_ros
        rt_audio_ros
        speech2command
        icog_face_tracker
    )
    _build_head ${blacklist[@]}
    _build_webui-js
}

_build_webui-js() {
    read_workspace
    cd $HR_WORKSPACE/HEAD/src/webui
    npm install
}

_build_full-head() {
    local blacklist=(
        eva_behavior
        speech2command
        testing_tools
        icog_face_tracker
    )
    _build_head ${blacklist[@]}
}

build_opencog() {
    read_workspace
    for repo in ${OPENCOG_REPOS[*]}
    do
        if [[ $repo != 'relex' && $repo != 'external-tools' ]]; then
            if [[ ! -d $HR_WORKSPACE/opencog/$repo/build ]]; then
                mkdir $HR_WORKSPACE/opencog/$repo/build
            fi
            cd $HR_WORKSPACE/opencog/$repo/build && cmake ..  && make -j$(nproc) && $SUDO make install
        fi
        if [[ $repo == 'relex' ]]; then
            cd $HR_WORKSPACE/opencog/$repo && JAVA_TOOL_OPTIONS=-Dfile.encoding=UTF8 ant build && $SUDO ant install
        fi
    done
}

help_build() {
cat << EOF
hr build <component> [<component>] ...

Build components

    head        Build only whitelist packages HEAD
    opencog     Build OpenCog components
EOF
}

clean_head() {
    read_workspace
    for repo in ${HR_REPOS[*]}; do
        cd $HR_WORKSPACE/$repo
        if [[ -d .catkin_tools ]]; then
            catkin clean -y || catkin clean -a
        fi
    done
}

clean_opencog() {
    read_workspace
    rm -rf ~/.cache/guile
    rm -rf ~/.hr/cache/oc_aiml
    if [[ ! -z $HR_WORKSPACE ]]; then
        for repo in ${OPENCOG_REPOS[*]}
        do
            if [[ $repo != 'relex' && $repo != 'external-tools' ]]; then
                $SUDO rm -rf $HR_WORKSPACE/opencog/$repo/build
            fi
        done
    fi
    $SUDO rm -rf /usr/local/include/opencog
    $SUDO rm -rf /usr/local/lib/opencog
    $SUDO rm -rf /usr/local/share/opencog
    $SUDO rm -f /usr/local/bin/cogserver
    $SUDO rm -f /usr/local/etc/cogserver.conf
    $SUDO rm -f /usr/local/etc/opencog.conf
    $SUDO rm -f /usr/local/lib/libcogutil.so
}

help_clean() {
cat << EOF
hr clean <component> [<component>] ...

Clean up components

    head    Clean up HEAD builds
    opencog Clean up OpenCog builds, cache and models
EOF
}

check_local_changes() {
    read_workspace
    for repo in ${OPENCOG_REPOS[*]}
    do
        if [[ -d $HR_WORKSPACE/opencog/$repo ]]; then
            cd $HR_WORKSPACE/opencog/$repo
            branch=$(git rev-parse --abbrev-ref HEAD)
            if [[ $branch != 'master' ]]; then
                warn "HEAD branch is not master $(pwd)" 1>&2
                return 1
            fi
            if [[ $(git status -uno --porcelain|wc -c) != 0 ]]; then
                warn "Plese commit the change(s) $(pwd)" 1>&2
                warn $(git status --porcelain) 1>&2
                return 1
            fi
            if [[ $(git diff --name-only master origin/master|wc -c) != 0 ]]; then
                warn "Master branch is not synchronized with origin $(pwd)" 1>&2
                return 1
            fi
        fi
    done
    cd $HR_WORKSPACE
}

switch_opencog_repo() {
    read_workspace
    DOMAIN=${1}
    [[ -z $DOMAIN ]] && error "Wrong arguments, either hansonrobotics or opencog" && exit
    check_local_changes || exit 1
    warn "Switching to $DOMAIN repositories"
    for repo in ${OPENCOG_REPOS[*]}
    do
        cd $HR_WORKSPACE
        if [[ -d $HR_WORKSPACE/opencog/$repo ]]; then
            info "Set [$repo] origin to https://github.com/$DOMAIN/$repo"
            cd opencog/$repo
            git remote remove old || true
            git remote rename origin old
            git remote add -f origin https://github.com/$DOMAIN/$repo
            git branch master -u origin/master
            git reset --hard origin/master
        else
            clone $DOMAIN $repo opencog
        fi
    done
}

set_normal_opencog() {
    switch_opencog_repo hansonrobotics
    update_opencog
}

set_dev_opencog() {
    switch_opencog_repo opencog
    update_opencog
}

help_cmd() {
cat << EOF
hr cmd <command> [args]

Some useful commands:

    switch_opencog_repo <hansonrobotics|opencog>        Set the upstream of OpenCog repositories

EOF
}

############# End of Functions #############

############# Main #############
show_help() {
cat << EOF
Hanson Robotics Software Management Tool

Usage: hr <command> [<args>]

  Supported commands:

    init [workspace]                        Init HR workspace. The default is ~/hansonrobotics
    install <component> [<component>] ...   Install components
    uninstall <component> [<component>] ... Uninstall components
    build <component> [<component>] ...     Build components
    update <component> [<component>] ...    Update components
    clean <component> [<component>] ...     Clean up components
    cmd <function> [<args>]                 Run any pre-defined function
    run [robot name] [arguments]            Run robot
    stop                                    Stop robot
    env                                     Show HR environment variables
    version                                 Show version
EOF
}

execute() {
    case "$1" in
        install|uninstall|build|cmd|init|clean|env|update|run|stop|version)
            command=$1
            shift
            hr_${command} $@
            ;;
        *)
            warn "Unknown argument $1"
            show_help
            exit 1
            ;;
    esac
}

if [[ ! $(readlink -f ${BASH_SOURCE[0]}) == $(readlink -f $0) ]]; then return; fi
if [[ $# == 0 ]]; then show_help; exit 0; fi
execute $@
############# End of Main #############
